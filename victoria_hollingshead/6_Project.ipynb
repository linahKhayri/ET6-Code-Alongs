{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Fundamentals: Project\n",
    "\n",
    "* * * \n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "### Learning Objectives \n",
    "    \n",
    "* Apply the skills you have learned in this workshop series to a health dataset.\n",
    "* Understand how to navigate file structures in Jupyter.\n",
    "* Apply Pandas methods to concatenate dataframes, clean up data, count and group values, and visualize correlations. \n",
    "* Use your search engine to look up how functions and methods work.\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "### Icons Used in This Notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "‚ö†Ô∏è **Warning:** Heads-up about tricky stuff or common mistakes.<br>\n",
    "üìù **Poll:** A Zoom poll to help you learn!\n",
    "\n",
    "\n",
    "### Sections\n",
    "1. [üöÄ Project](#project)\n",
    "2. [Step 1: Import the Data](#data)\n",
    "3. [Step 2: Data Cleaning](#clean)\n",
    "4. [Step 3: Data Analysis](#eda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='project'></a>\n",
    "\n",
    "# üöÄ Project\n",
    "\n",
    "### Data: California Health Interview Survey\n",
    "The [California Health Interview Survey (CHIS)](https://healthpolicy.ucla.edu/chis/Pages/default.aspx) is the nation's largest state health survey and a critical source of data on Californians as well as on the state's various racial and ethnic groups. The data has been altered for demonstration purposes.\n",
    "\n",
    "The data has the following columns:\n",
    "\n",
    "- `general_health`: Self-Reported assessment of general health\n",
    "- `veg_perweek`: How many vegetables consumed per week\n",
    "- `feel_left_out`: How often feeling left out\n",
    "- `poverty_level`: Poverty level as Times of 100% Federal Poverty Line (FPL)\n",
    "- `household_tenure`: Self-Reported household tenure\n",
    "- `interview_language`: Language of interview\n",
    "\n",
    "For this project, the goal we want to accomplish is **visualizing the relationship between poverty level and general health**. We will bring together basic programming and data science techniques you have learned to do this.\n",
    "\n",
    "üîî **Question**: Are there other research questions you could imagine asking with this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='data'></a>\n",
    "\n",
    "# Step 1: Importing Data \n",
    "\n",
    "Before we import our data, a few words on **filepaths**. \n",
    "\n",
    "A filepath is the location of a file on your system. There are two kinds of filepaths:\n",
    "\n",
    "* **absolute**: The filepath from the top level folder of your system.\n",
    "* **relative**: The filepath relative to the current working directory (i.e. this notebook's location). \n",
    "\n",
    "<img src=\"../img/filetree.png\" alt=\"Absolute and relative filepaths\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `listdir()`\n",
    "\n",
    "When you are figuring out what filepath to use, you can use `os.listdir([PATH])` to list all subdirectories in a path. For example, let's see what directories are available to us in the current folder (noted with a dot `.`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['misc',\n",
       " 'README.md',\n",
       " 'chis_data',\n",
       " 'gapminder_gni.csv',\n",
       " 'California_County_Boundaries',\n",
       " '6_Project.ipynb',\n",
       " 'gapminder.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking up the items in the folder after moving up one level works like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['victoria_hollingshead',\n",
       " 'LICENSE',\n",
       " 'anjali_n_ravunniarath',\n",
       " 'README.md',\n",
       " 'ameya_naik',\n",
       " '.gitignore',\n",
       " '.ls-lint.yml',\n",
       " '.git',\n",
       " '.assets',\n",
       " '.vscode']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Tip:** In Jupyter Lab's File Browser (the folder icon in top left of your screen),  you can navigate to a folder, right-click on a file and select `Copy Path` to get the absolute filepath of a file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Locating the Data\n",
    "\n",
    "Try to locate the files in the \"chis_data\" folder, which is in the \"data\" folder, which is in the main \"Python-Intermediate\" folder. Using `pd.read_csv()`, read in all three data frames and assign them to the three variables defined below.\n",
    "\n",
    "üí° **Tip**: You can use Jupyter Lab's File Browser to the left of your screen to get a sense of where the \"chis_data\" folder is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# YOUR CODE HERE\n",
    "df_eng = ...\n",
    "df_esp = ...\n",
    "df_other = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Concatenating DataFrames\n",
    "\n",
    "Look up the [documentation for Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/general_functions.html), and see if you can find a function that **concatenates** the three DataFrames we have now. Save the concatenated list in a new variable called `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîî **Question**: Let's take a look at the final data frame.\n",
    "\n",
    "1. How many rows and columns are there in the concatenated DataFrame?\n",
    "2. How many numeric columns are there in the dataset?\n",
    "3. What data type are the values in the `poverty_level` column?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's reset the index\n",
    "df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "\n",
    "# Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we will want to remove some missing values in a DataFrame. Have a look at the `general_health` column and find the missing values using the `.isna()` method. Then, use `.sum()` to sum the amount of undefined (NaN) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of the non-existent values in this column with the `.dropna()` method. Look through the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) to see how to do this.\n",
    "\n",
    "üí° **Tip**: Use the `subset` argument to select a specific column to remove values from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "\n",
    "# Step 3: Data Analysis\n",
    "\n",
    "Now that we have preprocessed data, we want to analyze it. Recall that our goal is to visualize a relationship between poverty level and general health. Before we do this, we should get a better grasp of what is in our data.\n",
    "\n",
    "## Counting Values\n",
    "The first thing we will want to do is count values of poverty levels: we want to see how many levels there are, and how the data are distributed. First, run `value_counts()` on the `poverty_level` column. \n",
    "\n",
    "üìù **Poll PyFun 6-1**: Look through the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) for `value_counts()`. What parameter can you use to normalize the output?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating a Function\n",
    "\n",
    "It turns out that poverty is expressed \"as Times of 100% Federal Poverty Line (FPL)\".\n",
    "For instance, `\"100-199%\" FPL\"` means that the row's income was 1-1.99 times the FPL.\n",
    "One approach to this statistic could be to see if we can find differences in general health for people **below and above the poverty line**. \n",
    "\n",
    "To do this, we can create a function that takes in values of the `poverty_level` column and outputs whether that value is above or below the poverty line.\n",
    "\n",
    "1. Create a new function called `assign_level`. It takes one parameter, which we'll call `i`.\n",
    "2. If `i` is `\"0-99% FPL\"`, return 0. In all other cases, return 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying a Function\n",
    "\n",
    "Recall that we can use the `apply()` method in Pandas to apply our new function to the `poverty_level` column of our DataFrame. We also want to save the output of this `apply()` method to a new column in our DataFrame. \n",
    "\n",
    "1. Use the `apply()` method on the `poverty_level` column. Pass your `assign_level` function as the argument.\n",
    "3. Save the result of this operation in a new column in your `df`, called `above_poverty_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting a DataFrame\n",
    "\n",
    "In order to create two bar plots of general health ‚Äì for people above and below the poverty line ‚Äì we can create two DataFrames for just these groups. We can then plot the values in these DataFrames \"on top of\" one another in a barplot.\n",
    "\n",
    "Recall that we can subset DataFrames with Boolean masks. For instance, say we have a DataFrame `counts` with a column `A`. If we want to create a new DataFrame called `above_800`, which only contains the values over 800 in column `A` of `counts`, we would write:\n",
    "\n",
    "```\n",
    "above_800 = counts[counts['A'] > 800]\n",
    "```\n",
    "\n",
    "Let's perform the same operation on our data.\n",
    "\n",
    "1. Create a new DataFrame, `df_below`. It will be a subset of our `df`, based on the condition that the value in `above_poverty_line` is 0.\n",
    "2. Create a new DataFrame, `df_above`. It will be a subset of our `df`, based on the condition that the value in `above_poverty_line` is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df_below = ...\n",
    "df_above = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Visualization\n",
    "\n",
    "Finally, let's create our bar plots. We will create 2 plots in 1 cell, which will be plotted on top of one another. \n",
    "\n",
    "Fill in the blanks below, following the steps. \n",
    "\n",
    "1. Run a **normalized** `value_counts()` on the `general_health` column of `df_above` and `df_below`.\n",
    "2. We are running `plot()` on the output of the resulting DataFrame. Enter the values for two arguments: `kind` must be set to `bar`, and `alpha` must be set to `.5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df_above[...].value_counts(...).plot(kind=..., alpha=...);\n",
    "df_below[...].value_counts(...).plot(kind=..., alpha=...,color='maroon');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Poll PyFun 6-2**:What is the `alpha` parameter doing? Read through the [documentation](https://pandas.pydata.org/docs/user_guide/visualization.html) to find out.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéâ Well Done!\n",
    "\n",
    "Today's project took us through a data science workflow in Python:\n",
    "\n",
    "- Importing multiple .csv files\n",
    "- Exploratory Data Analysis\n",
    "- Basic visualization\n",
    "\n",
    "### üí° Tip: More Workshops!\n",
    "\n",
    "D-Lab teaches workshops that allow you to practice more with DataFrames and visualization.\n",
    "\n",
    "- To learn more about Pandas and data wrangling, check out D-Lab's [Python Data Wrangling workshop](https://github.com/dlab-berkeley/Python-Data-Wrangling).\n",
    "- To learn more about data visualization, check out D-Lab's [Python Data Visualization workshop](https://github.com/dlab-berkeley/Python-Data-Visualization).\n",
    "- To learn more about text analysis, check out D-Lab's [Python Text Analysis workshop](https://github.com/dlab-berkeley/Python-Text-Analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "## ‚ùó Key Points\n",
    "\n",
    "* File structures can be navigated using absolute and relative file paths.\n",
    "* The `.dropna()` method in Pandas removes missing values from a `DataFrame` or `Series`.\n",
    "* Custom Functions can be applied to the axis of a DataFrame using `apply()`.\n",
    "* Subsetting DataFrames based on some condition can help with creating comparative visualizations.    \n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
